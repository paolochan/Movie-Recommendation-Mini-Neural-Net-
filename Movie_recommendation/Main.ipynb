{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e609b898-cb04-4384-9580-70a96fad2238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b38c9a4d-8eb6-4aa7-abcd-28f36e75727e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/paolochan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee44cf37-f841-4582-ade2-10b7bb0822b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Part one: Gathering data\n",
    "\n",
    "#movies\n",
    "df_movies = pd.read_csv(\"imdb_top_1000.csv\")  # or whatever your filename is\n",
    "df_movies[\"Series_Title\"].head()\n",
    "\n",
    "#Synthetic user data\n",
    "np.random.seed(12)\n",
    "user_ratings = {title: np.round(np.random.uniform(0.0, 1.0), 2) for title in df_movies['Series_Title']}\n",
    "\n",
    "# Assign to DataFrame\n",
    "df_movies['User_Rating'] = df_movies['Series_Title'].map(user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ea04014-9762-4f07-9f5a-9b962441ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: preprocessing data\n",
    "\n",
    "## Cleaning \n",
    "df_movies= df_movies.drop([\"Gross\", \"Poster_Link\", \"Certificate\", \"No_of_Votes\",\"Meta_score\",\"Runtime\"], axis=1) ## Drop data we don't want to use\n",
    "df_movies[\"Series_Title\"]= df_movies[\"Series_Title\"].str.lower().str.strip() \n",
    "df_movies[\"Genre\"]= df_movies[\"Genre\"].str.lower().str.strip()\n",
    "df_movies['Genre_List'] = df_movies['Genre'].str.split(', ') #splitting genres into a list instead of string\n",
    "\n",
    "## Merge the actors into one list \n",
    "df_movies[\"Stars\"] = df_movies.apply(\n",
    "    lambda row: [\n",
    "        str(row[\"Star1\"]).lower().strip(),\n",
    "        str(row[\"Star2\"]).lower().strip(),\n",
    "        str(row[\"Star3\"]).lower().strip(),\n",
    "        str(row[\"Star4\"]).lower().strip()\n",
    "    ], axis=1\n",
    ")\n",
    "actor_counts = Counter(actor for sublist in df_movies['Stars'] for actor in sublist) # count actor instances\n",
    "\n",
    "top_actors = [actor for actor, count in actor_counts.items() if count >= 3]  # top actors appear more than 5 times\n",
    "# Keep only top actors in each movie\n",
    "def filter_top_actors(stars_list):\n",
    "    return [actor for actor in stars_list if actor in top_actors]\n",
    "df_movies['Stars'] = df_movies['Stars'].apply(filter_top_actors)\n",
    "\n",
    "#Normalize IMDB rating \n",
    "scaler = MinMaxScaler()\n",
    "df_movies['Nrating']= scaler.fit_transform(df_movies[['IMDB_Rating']])\n",
    "\n",
    "\n",
    "#Encoding \n",
    "\n",
    "#encoding genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "##mlb.fit_transform([df_movies['Genre_List']])\n",
    "genre_encoded = pd.DataFrame(\n",
    "    mlb.fit_transform(df_movies['Genre_List']), columns=mlb.classes_, index=df_movies['Series_Title'])\n",
    "\n",
    "#Encoding Director\n",
    "top_25_directors = df_movies['Director'].value_counts().nlargest(25).index\n",
    "df_movies['Director'] = df_movies['Director'].where(df_movies['Director'].isin(top_25_directors), 'Other')\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "director_encoded= pd.DataFrame(ohe.fit_transform(df_movies[['Director']]),columns=ohe.get_feature_names_out(['Director']),index=df_movies['Series_Title'])\n",
    "\n",
    "#Encoding actors\n",
    "mlba = MultiLabelBinarizer()\n",
    "actor_encoded = pd.DataFrame(mlba.fit_transform(df_movies['Stars']), columns= mlba.classes_, index= df_movies['Series_Title'])\n",
    "\n",
    "\n",
    "\n",
    "#Tokenizing and Embedding of overview\n",
    "df_movies['tokens'] = df_movies['Overview'].fillna('').apply(word_tokenize)\n",
    "\n",
    "w2v_model = Word2Vec(sentences=df_movies[\"tokens\"], vector_size=100, window=5, min_count=2, workers=4)\n",
    "def average_vector(tokens) :\n",
    "    vectors = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(w2v_model.vector_size)\n",
    "df_movies['overview_vector'] = df_movies['tokens'].apply(average_vector)\n",
    "\n",
    "X = np.hstack([\n",
    "    genre_encoded.values,\n",
    "    actor_encoded.values,\n",
    "    director_encoded.values,\n",
    "    np.vstack(df_movies['overview_vector']),\n",
    "    df_movies[['Nrating']].values\n",
    "])\n",
    "y=df_movies['User_Rating'].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cad7967-dbaf-4dd1-b47d-6993701c31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=12\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdf7a935-cd8e-47a1-8df5-8cae48808ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:39:34.719749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-05-12 13:39:34.801082: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 25ms/step - loss: 0.0926 - mae: 0.2596 - val_loss: 0.0833 - val_mae: 0.2469\n",
      "Epoch 2/20\n",
      "21/23 [==========================>...] - ETA: 0s - loss: 0.0905 - mae: 0.2571"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:39:37.436586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0909 - mae: 0.2578 - val_loss: 0.0839 - val_mae: 0.2416\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0847 - mae: 0.2488 - val_loss: 0.0810 - val_mae: 0.2409\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0830 - mae: 0.2463 - val_loss: 0.0847 - val_mae: 0.2493\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0829 - mae: 0.2439 - val_loss: 0.0836 - val_mae: 0.2475\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0834 - mae: 0.2451 - val_loss: 0.0861 - val_mae: 0.2513\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0853 - mae: 0.2470 - val_loss: 0.0794 - val_mae: 0.2413\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0810 - mae: 0.2427 - val_loss: 0.0827 - val_mae: 0.2457\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0794 - mae: 0.2400 - val_loss: 0.0782 - val_mae: 0.2383\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0779 - mae: 0.2372 - val_loss: 0.0786 - val_mae: 0.2385\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0781 - mae: 0.2366 - val_loss: 0.0781 - val_mae: 0.2388\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0743 - mae: 0.2299 - val_loss: 0.0785 - val_mae: 0.2397\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0771 - mae: 0.2333 - val_loss: 0.0824 - val_mae: 0.2401\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0733 - mae: 0.2279 - val_loss: 0.0788 - val_mae: 0.2404\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0664 - mae: 0.2168 - val_loss: 0.0793 - val_mae: 0.2412\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0696 - mae: 0.2200 - val_loss: 0.0790 - val_mae: 0.2402\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0679 - mae: 0.2169 - val_loss: 0.0821 - val_mae: 0.2462\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0709 - mae: 0.2209 - val_loss: 0.0836 - val_mae: 0.2412\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0698 - mae: 0.2177 - val_loss: 0.0786 - val_mae: 0.2398\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0626 - mae: 0.2100 - val_loss: 0.0799 - val_mae: 0.2408\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.0980 - mae: 0.2681\n",
      "Test Accuracy: 0.2681\n"
     ]
    }
   ],
   "source": [
    "#Using Keras to make a neural network moddel\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error',   \n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,              # Number of full passes over the training data\n",
    "    batch_size=32,          # Number of samples per gradient update\n",
    "    validation_split=0.1,   # Use 10% of training data for validation\n",
    "    verbose=1  )             # Print progress bar\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7da9b391-938b-495f-9690-49b415fdd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_genres=[]\n",
    "def newInfo():\n",
    "    print(\"Please enter details on a new movie:\")\n",
    "    title =input(\"Title: \").strip().lower()\n",
    "\n",
    "    #getting available genres\n",
    "    valid_genres = [\n",
    "    'action', 'adventure', 'animation', 'biography', 'comedy', 'crime',\n",
    "    'drama', 'family', 'fantasy', 'film-noir', 'history', 'horror',\n",
    "    'music', 'musical', 'mystery', 'romance', 'sci-fi', 'sport',\n",
    "    'thriller', 'war', 'western'\n",
    "]\n",
    "    while True:\n",
    "        print(f\"Available genres:\\n{', '.join(valid_genres)}\")\n",
    "        genres = input(\"Enter genres (comma-separated): \").strip().lower().split(',')\n",
    "        genres = [g.strip() for g in genres]\n",
    "        \n",
    "        if all(g in valid_genres for g in genres):\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ One or more genres are invalid. Please choose only from the listed genres.\\n\")\n",
    "\n",
    "    actors = input(\"Main actors (comma-separated): \").strip().lower().split(',')\n",
    "    actors = [a.strip() for a in actors]\n",
    "    director = input(\"Director: \").strip().lower()\n",
    "    imdb_rating = float(input(\"IMDB rating (0.0–10.0): \"))\n",
    "    overview = input(\"Overview: \").strip().lower()\n",
    "    return {\n",
    "        \"Series_Title\": title,\n",
    "        \"Genre_List\": genres,\n",
    "        \"Stars\": actors,\n",
    "        \"Director\": director,\n",
    "        \"IMDB_Rating\": imdb_rating,\n",
    "        \"Overview\":overview\n",
    "    \n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b68c70b9-e668-48a8-a590-467db58bd137",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_user_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mhstack([genre_vec, actor_vec, director_vec, overview_vec, rating_norm])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# === Run the prediction ===\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m new_movie \u001b[38;5;241m=\u001b[39m \u001b[43mget_user_input\u001b[49m()\n\u001b[1;32m     21\u001b[0m X_new \u001b[38;5;241m=\u001b[39m preprocess_new_movie(new_movie, w2v_model, mlb, mlba, ohe, scaler)\n\u001b[1;32m     22\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_new\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_user_input' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc615bac-ea05-4bc4-9577-76c963a084db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter details on a new movie:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Title:  Sinners\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available genres:\n",
      "action, adventure, animation, biography, comedy, crime, drama, family, fantasy, film-noir, history, horror, music, musical, mystery, romance, sci-fi, sport, thriller, war, western\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter genres (comma-separated):  horror, adventure\n",
      "Main actors (comma-separated):  Michael B. Jordan, Hailee Steinfeld\n",
      "Director:  Ryan Coogler\n",
      "IMDB rating (0.0–10.0):  8.1\n",
      "Overview:  Trying to leave their troubled lives behind, twin brothers return to their Mississippi hometown to start again, only to discover that an even greater evil is waiting to welcome them back.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolochan/opt/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolochan/opt/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 199ms/step\n",
      "\n",
      "Predicted score: 0.58\n",
      "❌ User probably won't like this movie.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_new_movie(movie, w2v_model, genre_encoder, actor_encoder, director_encoder, scaler):\n",
    "    genre_vec = genre_encoder.transform([movie[\"Genre_List\"]])\n",
    "\n",
    "    top_actors = actor_encoder.classes_\n",
    "    movie_actors = [actor for actor in movie[\"Stars\"] if actor in top_actors]\n",
    "    actor_vec = actor_encoder.transform([movie_actors])\n",
    "\n",
    "    director = movie[\"Director\"].strip()\n",
    "    if director not in director_encoder.categories_[0]:\n",
    "        director = \"Other\"\n",
    "    director_vec = director_encoder.transform([[director]])\n",
    "\n",
    "    tokens = word_tokenize(movie[\"Overview\"])\n",
    "    vecs = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    overview_vec = np.mean(vecs, axis=0) if vecs else np.zeros(w2v_model.vector_size)\n",
    "    overview_vec = overview_vec.reshape(1, -1)\n",
    "\n",
    "    rating_norm = scaler.transform([[movie[\"IMDB_Rating\"]]])\n",
    "\n",
    "    return np.hstack([genre_vec, actor_vec, director_vec, overview_vec, rating_norm])\n",
    "\n",
    "# === Run the prediction ===\n",
    "new_movie = newInfo()\n",
    "X_new = preprocess_new_movie(new_movie, w2v_model, mlb, mlba, ohe, scaler)\n",
    "score = model.predict(X_new.reshape(1, -1))[0][0]\n",
    "\n",
    "print(f\"\\nPredicted score: {score:.2f}\")\n",
    "print(\"✅ User will likely like this movie!\" if score > 0.6 else \"❌ User probably won't like this movie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6cd35-10ca-4377-88fb-7238c795ad35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
